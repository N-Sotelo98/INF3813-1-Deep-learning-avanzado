{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset \n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import src.utils as utils\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "## REGRESION\n",
    "\n",
    "# Sample Dataset Class\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, data, targets, seq_len):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data (torch.Tensor): Input data of shape (num_samples, seq_len, num_features)\n",
    "            targets (torch.Tensor): Target data of shape (num_samples,)\n",
    "            seq_len (int): Sequence length\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.targets[idx]\n",
    "\n",
    "# CNN Module\n",
    "class CNNBlock_Reg(nn.Module):\n",
    "    def __init__(self, input_channels, num_filters, kernel_size):\n",
    "        super(CNNBlock_Reg, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=input_channels, out_channels=num_filters, kernel_size=kernel_size, padding=kernel_size // 2)\n",
    "        self.conv2 = nn.Conv1d(in_channels=num_filters, out_channels=num_filters, kernel_size=kernel_size, padding=kernel_size // 2)\n",
    "        self.pool = nn.AdaptiveAvgPool1d(1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x (torch.Tensor): Input of shape (batch_size, seq_len, num_features)\n",
    "        Returns:\n",
    "            torch.Tensor: Output features (batch_size, num_filters)\n",
    "        \"\"\"\n",
    "        x = x.permute(0, 2, 1)  # Change to (batch_size, num_features, seq_len)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x).squeeze(-1)  # Global average pooling\n",
    "        return x\n",
    "\n",
    "# Temporal Fusion Transformer (simplified for demonstration)\n",
    "class TemporalFusionTransformer_Reg(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_heads, num_layers):\n",
    "        super(TemporalFusionTransformer_Reg, self).__init__()\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=hidden_size, nhead=num_heads, dim_feedforward=256)\n",
    "        self.transformer = nn.TransformerEncoder(self.encoder_layer, num_layers=num_layers)\n",
    "        self.input_projection = nn.Linear(input_size, hidden_size)\n",
    "        self.output_projection = nn.Linear(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x (torch.Tensor): Input of shape (batch_size, seq_len, input_size)\n",
    "        Returns:\n",
    "            torch.Tensor: Output features (batch_size, hidden_size)\n",
    "        \"\"\"\n",
    "        x = self.input_projection(x)\n",
    "        x = x.permute(1, 0, 2)  # Change to (seq_len, batch_size, hidden_size) for Transformer\n",
    "        x = self.transformer(x)\n",
    "        x = x.mean(dim=0)  # Aggregate across sequence length\n",
    "        x = self.output_projection(x)\n",
    "        return x\n",
    "\n",
    "# Hybrid Model\n",
    "class HybridTFTCNN_Reg(nn.Module):\n",
    "    def __init__(self, input_size, cnn_filters, kernel_size, transformer_hidden_size, num_heads, num_layers, output_size):\n",
    "        super(HybridTFTCNN_Reg, self).__init__()\n",
    "        self.cnn_block = CNNBlock_Reg(input_channels=input_size, num_filters=cnn_filters, kernel_size=kernel_size)\n",
    "        self.tft_block = TemporalFusionTransformer_Reg(input_size=input_size, hidden_size=transformer_hidden_size, num_heads=num_heads, num_layers=num_layers)\n",
    "        self.final_fc = nn.Linear(cnn_filters + transformer_hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x (torch.Tensor): Input of shape (batch_size, seq_len, input_size)\n",
    "        Returns:\n",
    "            torch.Tensor: Output prediction (batch_size, output_size)\n",
    "        \"\"\"\n",
    "        cnn_features = self.cnn_block(x)\n",
    "        tft_features = self.tft_block(x)\n",
    "        combined_features = torch.cat([cnn_features, tft_features], dim=-1)\n",
    "        output = self.final_fc(combined_features)\n",
    "        return output\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            X (torch.Tensor or np.ndarray): Input data of shape (batch_size, seq_len, input_size)\n",
    "        Returns:\n",
    "            np.ndarray: Predicted output values\n",
    "        \"\"\"\n",
    "        # Ensure the model is in evaluation mode\n",
    "        self.eval()\n",
    "\n",
    "        # Convert input to torch tensor if it's a NumPy array\n",
    "        if isinstance(X, np.ndarray):\n",
    "            X = torch.tensor(X, dtype=torch.float32)\n",
    "\n",
    "        # Use no_grad to disable gradient computation during prediction\n",
    "        with torch.no_grad():\n",
    "            predictions = self.forward(X)\n",
    "\n",
    "        # Convert predictions to a NumPy array and return\n",
    "        return predictions.numpy()\n",
    "\n",
    "# # Example Usage\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Dummy Data\n",
    "#     num_samples = 1000\n",
    "#     seq_len = 24\n",
    "#     num_features = 10\n",
    "#     x_data = torch.randn(num_samples, seq_len, num_features)\n",
    "#     y_data = torch.randn(num_samples, 1)\n",
    "\n",
    "#     # Dataset and DataLoader\n",
    "#     dataset = TimeSeriesDataset(x_data, y_data, seq_len=seq_len)\n",
    "#     dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "#     # Model\n",
    "#     model = HybridTFTCNN(\n",
    "#         input_size=num_features,\n",
    "#         cnn_filters=16,\n",
    "#         kernel_size=3,\n",
    "#         transformer_hidden_size=32,\n",
    "#         num_heads=4,\n",
    "#         num_layers=2,\n",
    "#         output_size=1\n",
    "#     )\n",
    "\n",
    "#     # Training Setup\n",
    "#     criterion = nn.MSELoss()\n",
    "#     optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "#     # Training Loop\n",
    "#     for epoch in range(10):\n",
    "#         model.train()\n",
    "#         epoch_loss = 0\n",
    "#         for x_batch, y_batch in dataloader:\n",
    "#             optimizer.zero_grad()\n",
    "#             predictions = model(x_batch)\n",
    "#             loss = criterion(predictions, y_batch)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "#             epoch_loss += loss.item()\n",
    "\n",
    "#         print(f\"Epoch {epoch + 1}, Loss: {epoch_loss / len(dataloader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([32, 1])\n"
     ]
    }
   ],
   "source": [
    "### CLASIFICACION\n",
    "\n",
    "\n",
    "# Define the CNN Block\n",
    "class CNNBlock_Class(nn.Module):\n",
    "    def __init__(self, input_dim, cnn_channels, kernel_size=3):\n",
    "        super(CNNBlock_Class, self).__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=input_dim, out_channels=cnn_channels, kernel_size=kernel_size, padding=kernel_size//2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(in_channels=cnn_channels, out_channels=cnn_channels, kernel_size=kernel_size, padding=kernel_size//2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Expecting input shape: (batch_size, seq_len, input_dim)\n",
    "        x = x.permute(0, 2, 1)  # Reshape to (batch_size, input_dim, seq_len) for Conv1D\n",
    "        x = self.cnn(x)\n",
    "        x = x.permute(0, 2, 1)  # Reshape back to (batch_size, seq_len, cnn_channels)\n",
    "        return x\n",
    "\n",
    "# Define the Temporal Fusion Transformer (TFT) Block\n",
    "class TFTBlock_Class(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_heads, dropout=0.1):\n",
    "        super(TFTBlock_Class, self).__init__()\n",
    "        self.multihead_attn = nn.MultiheadAttention(embed_dim=input_dim, num_heads=num_heads, dropout=dropout)\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, input_dim),\n",
    "        )\n",
    "        self.norm1 = nn.LayerNorm(input_dim)\n",
    "        self.norm2 = nn.LayerNorm(input_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Expecting input shape: (seq_len, batch_size, input_dim)\n",
    "        attn_output, _ = self.multihead_attn(x, x, x)\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.norm2(x + self.dropout(ff_output))\n",
    "        return x\n",
    "\n",
    "# Combine CNN and TFT into a Hybrid Model\n",
    "class HybridTFTCNN_Class(nn.Module):\n",
    "    def __init__(self, input_dim, cnn_channels, tft_hidden_dim, tft_heads, seq_len, output_dim, dropout=0.1):\n",
    "        super(HybridTFTCNN_Class, self).__init__()\n",
    "        self.cnn_block = CNNBlock_Class(input_dim, cnn_channels)\n",
    "        self.tft_block = TFTBlock_Class(input_dim=cnn_channels, hidden_dim=tft_hidden_dim, num_heads=tft_heads, dropout=dropout)\n",
    "        self.output_layer = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(seq_len * cnn_channels, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Input shape: (batch_size, seq_len, input_dim)\n",
    "        x = self.cnn_block(x)  # (batch_size, seq_len, cnn_channels)\n",
    "        x = x.permute(1, 0, 2)  # Reshape to (seq_len, batch_size, cnn_channels) for TFT\n",
    "        x = self.tft_block(x)  # (seq_len, batch_size, cnn_channels)\n",
    "        x = x.permute(1, 0, 2)  # Reshape back to (batch_size, seq_len, cnn_channels)\n",
    "        x = self.output_layer(x)  # Final output\n",
    "        return x\n",
    "\n",
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Hyperparameters\n",
    "    input_dim = 10       # Number of input features\n",
    "    cnn_channels = 16    # Number of CNN output channels\n",
    "    tft_hidden_dim = 32  # Hidden dimension in TFT block\n",
    "    tft_heads = 4        # Number of attention heads in TFT block\n",
    "    seq_len = 24         # Sequence length (e.g., 24 hours)\n",
    "    output_dim = 1       # Number of outputs (e.g., regression target)\n",
    "    dropout = 0.1\n",
    "\n",
    "    # Create the model\n",
    "    model = HybridTFTCNN_Class(input_dim, cnn_channels, tft_hidden_dim, tft_heads, seq_len, output_dim, dropout)\n",
    "\n",
    "    # Example Input: Batch of 32 sequences, each of length 24, with 10 features\n",
    "    example_input = torch.randn(32, seq_len, input_dim)\n",
    "\n",
    "    # Forward Pass\n",
    "    output = model(example_input)\n",
    "    print(\"Output shape:\", output.shape)  # Expected: (32, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "def preprocess_data(df, target_col, seq_len, categorical_cols, continuous_cols):\n",
    "    \"\"\"\n",
    "    Prepares the dataset for the Hybrid TFT-CNN model.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Input dataframe.\n",
    "        target_col (str): Name of the target column.\n",
    "        seq_len (int): Sequence length for time-series data.\n",
    "        categorical_cols (list): List of categorical column names.\n",
    "        continuous_cols (list): List of continuous column names.\n",
    "    \n",
    "    Returns:\n",
    "        np.array: Sequences of input features (num_samples, seq_len, num_features).\n",
    "        np.array: Corresponding target values (num_samples,).\n",
    "    \"\"\"\n",
    "    # Encode categorical variables\n",
    "    for col in categorical_cols:\n",
    "        le = LabelEncoder()\n",
    "        df[col] = le.fit_transform(df[col])\n",
    "\n",
    "    # Normalize continuous variables\n",
    "    scaler = MinMaxScaler()\n",
    "    df[continuous_cols] = scaler.fit_transform(df[continuous_cols])\n",
    "\n",
    "    # Create sequences\n",
    "    sequences = []\n",
    "    targets = []\n",
    "    for i in range(len(df) - seq_len):\n",
    "        seq_x = df.iloc[i:i + seq_len][np.concatenate([categorical_cols,continuous_cols])].values\n",
    "        seq_y = df.iloc[i + seq_len][target_col]\n",
    "        sequences.append(seq_x)\n",
    "        targets.append(seq_y)\n",
    "\n",
    "    return np.array(sequences), np.array(targets)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cmg</th>\n",
       "      <th>demanda</th>\n",
       "      <th>gx_Eólicas_Antofagasta</th>\n",
       "      <th>gx_Eólicas_Araucanía</th>\n",
       "      <th>gx_Eólicas_Atacama</th>\n",
       "      <th>gx_Eólicas_Biobío</th>\n",
       "      <th>gx_Eólicas_Coquimbo</th>\n",
       "      <th>gx_Eólicas_Los Lagos</th>\n",
       "      <th>gx_Eólicas_O’Higgins</th>\n",
       "      <th>gx_Solares_Antofagasta</th>\n",
       "      <th>...</th>\n",
       "      <th>emb_MELADO</th>\n",
       "      <th>emb_PANGUE</th>\n",
       "      <th>emb_POLCURA</th>\n",
       "      <th>emb_RALCO</th>\n",
       "      <th>emb_RAPEL</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>55.52</td>\n",
       "      <td>7992.914520</td>\n",
       "      <td>89.92</td>\n",
       "      <td>71.65</td>\n",
       "      <td>26.40</td>\n",
       "      <td>57.09</td>\n",
       "      <td>459.92</td>\n",
       "      <td>26.54</td>\n",
       "      <td>3.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>643.47</td>\n",
       "      <td>509.02</td>\n",
       "      <td>735.55</td>\n",
       "      <td>715.75</td>\n",
       "      <td>103.52</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55.52</td>\n",
       "      <td>7948.664819</td>\n",
       "      <td>72.62</td>\n",
       "      <td>79.50</td>\n",
       "      <td>10.70</td>\n",
       "      <td>58.19</td>\n",
       "      <td>388.12</td>\n",
       "      <td>22.47</td>\n",
       "      <td>1.76</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>643.63</td>\n",
       "      <td>508.90</td>\n",
       "      <td>735.57</td>\n",
       "      <td>715.75</td>\n",
       "      <td>103.52</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>55.52</td>\n",
       "      <td>7752.115956</td>\n",
       "      <td>35.16</td>\n",
       "      <td>77.97</td>\n",
       "      <td>1.90</td>\n",
       "      <td>48.44</td>\n",
       "      <td>304.78</td>\n",
       "      <td>13.95</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>643.79</td>\n",
       "      <td>508.81</td>\n",
       "      <td>735.60</td>\n",
       "      <td>715.73</td>\n",
       "      <td>103.52</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55.52</td>\n",
       "      <td>7523.577425</td>\n",
       "      <td>17.75</td>\n",
       "      <td>66.52</td>\n",
       "      <td>0.00</td>\n",
       "      <td>39.39</td>\n",
       "      <td>252.67</td>\n",
       "      <td>13.50</td>\n",
       "      <td>1.51</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>643.94</td>\n",
       "      <td>508.74</td>\n",
       "      <td>735.62</td>\n",
       "      <td>715.73</td>\n",
       "      <td>103.52</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55.52</td>\n",
       "      <td>7308.782546</td>\n",
       "      <td>8.89</td>\n",
       "      <td>51.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>41.75</td>\n",
       "      <td>278.55</td>\n",
       "      <td>15.77</td>\n",
       "      <td>3.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>644.08</td>\n",
       "      <td>508.75</td>\n",
       "      <td>735.62</td>\n",
       "      <td>715.73</td>\n",
       "      <td>103.52</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48131</th>\n",
       "      <td>0.00</td>\n",
       "      <td>9228.687500</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>645.91</td>\n",
       "      <td>508.77</td>\n",
       "      <td>735.03</td>\n",
       "      <td>721.98</td>\n",
       "      <td>104.52</td>\n",
       "      <td>2024</td>\n",
       "      <td>6</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48132</th>\n",
       "      <td>9.03</td>\n",
       "      <td>9903.786133</td>\n",
       "      <td>474.64</td>\n",
       "      <td>262.98</td>\n",
       "      <td>127.24</td>\n",
       "      <td>288.62</td>\n",
       "      <td>286.39</td>\n",
       "      <td>5.97</td>\n",
       "      <td>36.77</td>\n",
       "      <td>1493.65</td>\n",
       "      <td>...</td>\n",
       "      <td>645.92</td>\n",
       "      <td>508.71</td>\n",
       "      <td>735.07</td>\n",
       "      <td>722.04</td>\n",
       "      <td>104.53</td>\n",
       "      <td>2024</td>\n",
       "      <td>6</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48133</th>\n",
       "      <td>35.36</td>\n",
       "      <td>10463.607422</td>\n",
       "      <td>494.72</td>\n",
       "      <td>477.75</td>\n",
       "      <td>74.94</td>\n",
       "      <td>317.90</td>\n",
       "      <td>178.76</td>\n",
       "      <td>6.89</td>\n",
       "      <td>69.48</td>\n",
       "      <td>407.73</td>\n",
       "      <td>...</td>\n",
       "      <td>645.83</td>\n",
       "      <td>508.72</td>\n",
       "      <td>734.94</td>\n",
       "      <td>722.07</td>\n",
       "      <td>104.50</td>\n",
       "      <td>2024</td>\n",
       "      <td>6</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48134</th>\n",
       "      <td>69.48</td>\n",
       "      <td>10986.050781</td>\n",
       "      <td>303.65</td>\n",
       "      <td>654.46</td>\n",
       "      <td>28.13</td>\n",
       "      <td>365.90</td>\n",
       "      <td>85.30</td>\n",
       "      <td>2.12</td>\n",
       "      <td>71.48</td>\n",
       "      <td>166.14</td>\n",
       "      <td>...</td>\n",
       "      <td>645.78</td>\n",
       "      <td>508.71</td>\n",
       "      <td>734.92</td>\n",
       "      <td>722.07</td>\n",
       "      <td>104.51</td>\n",
       "      <td>2024</td>\n",
       "      <td>6</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48135</th>\n",
       "      <td>67.99</td>\n",
       "      <td>10960.001953</td>\n",
       "      <td>89.59</td>\n",
       "      <td>699.91</td>\n",
       "      <td>27.27</td>\n",
       "      <td>366.43</td>\n",
       "      <td>65.88</td>\n",
       "      <td>1.14</td>\n",
       "      <td>105.34</td>\n",
       "      <td>224.80</td>\n",
       "      <td>...</td>\n",
       "      <td>645.72</td>\n",
       "      <td>508.67</td>\n",
       "      <td>735.00</td>\n",
       "      <td>722.08</td>\n",
       "      <td>104.52</td>\n",
       "      <td>2024</td>\n",
       "      <td>6</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48136 rows × 110 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         cmg       demanda  gx_Eólicas_Antofagasta  gx_Eólicas_Araucanía  \\\n",
       "0      55.52   7992.914520                   89.92                 71.65   \n",
       "1      55.52   7948.664819                   72.62                 79.50   \n",
       "2      55.52   7752.115956                   35.16                 77.97   \n",
       "3      55.52   7523.577425                   17.75                 66.52   \n",
       "4      55.52   7308.782546                    8.89                 51.07   \n",
       "...      ...           ...                     ...                   ...   \n",
       "48131   0.00   9228.687500                    0.00                  0.00   \n",
       "48132   9.03   9903.786133                  474.64                262.98   \n",
       "48133  35.36  10463.607422                  494.72                477.75   \n",
       "48134  69.48  10986.050781                  303.65                654.46   \n",
       "48135  67.99  10960.001953                   89.59                699.91   \n",
       "\n",
       "       gx_Eólicas_Atacama  gx_Eólicas_Biobío  gx_Eólicas_Coquimbo  \\\n",
       "0                   26.40              57.09               459.92   \n",
       "1                   10.70              58.19               388.12   \n",
       "2                    1.90              48.44               304.78   \n",
       "3                    0.00              39.39               252.67   \n",
       "4                    0.00              41.75               278.55   \n",
       "...                   ...                ...                  ...   \n",
       "48131                0.00               0.00                 0.00   \n",
       "48132              127.24             288.62               286.39   \n",
       "48133               74.94             317.90               178.76   \n",
       "48134               28.13             365.90                85.30   \n",
       "48135               27.27             366.43                65.88   \n",
       "\n",
       "       gx_Eólicas_Los Lagos  gx_Eólicas_O’Higgins  gx_Solares_Antofagasta  \\\n",
       "0                     26.54                  3.03                    0.00   \n",
       "1                     22.47                  1.76                    0.00   \n",
       "2                     13.95                  0.65                    0.00   \n",
       "3                     13.50                  1.51                    0.00   \n",
       "4                     15.77                  3.25                    0.00   \n",
       "...                     ...                   ...                     ...   \n",
       "48131                  0.00                  0.00                    0.00   \n",
       "48132                  5.97                 36.77                 1493.65   \n",
       "48133                  6.89                 69.48                  407.73   \n",
       "48134                  2.12                 71.48                  166.14   \n",
       "48135                  1.14                105.34                  224.80   \n",
       "\n",
       "       ...  emb_MELADO  emb_PANGUE  emb_POLCURA  emb_RALCO  emb_RAPEL  year  \\\n",
       "0      ...      643.47      509.02       735.55     715.75     103.52  2019   \n",
       "1      ...      643.63      508.90       735.57     715.75     103.52  2019   \n",
       "2      ...      643.79      508.81       735.60     715.73     103.52  2019   \n",
       "3      ...      643.94      508.74       735.62     715.73     103.52  2019   \n",
       "4      ...      644.08      508.75       735.62     715.73     103.52  2019   \n",
       "...    ...         ...         ...          ...        ...        ...   ...   \n",
       "48131  ...      645.91      508.77       735.03     721.98     104.52  2024   \n",
       "48132  ...      645.92      508.71       735.07     722.04     104.53  2024   \n",
       "48133  ...      645.83      508.72       734.94     722.07     104.50  2024   \n",
       "48134  ...      645.78      508.71       734.92     722.07     104.51  2024   \n",
       "48135  ...      645.72      508.67       735.00     722.08     104.52  2024   \n",
       "\n",
       "       month  day  day_of_week  hour  \n",
       "0          1    1            1     0  \n",
       "1          1    1            1     1  \n",
       "2          1    1            1     2  \n",
       "3          1    1            1     3  \n",
       "4          1    1            1     4  \n",
       "...      ...  ...          ...   ...  \n",
       "48131      6   28            4    15  \n",
       "48132      6   28            4    16  \n",
       "48133      6   28            4    17  \n",
       "48134      6   28            4    18  \n",
       "48135      6   28            4    19  \n",
       "\n",
       "[48136 rows x 110 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'../data/df_final_metadata.csv')\n",
    "df = df.sort_values(by='fecha_hora', ascending=True)\n",
    "dt = df['fecha_hora'].copy()\n",
    "y_real = df['cmg'].copy()\n",
    "df = df.iloc[:,1:].copy()\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a split point (e.g., 80% train, 20% test)\n",
    "split_point = int(0.9 * len(df))\n",
    "\n",
    "# Split the data\n",
    "train_val_df = df[:split_point].copy()\n",
    "test_df = df[split_point:].copy()\n",
    "test_dt = dt[split_point:].copy()\n",
    "test_cmg = y_real[split_point:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_point_val = int(0.8 * len(train_val_df))  # 80% train, 20% validation\n",
    "train_df = train_val_df[:split_point_val].copy()\n",
    "val_df = train_val_df[split_point_val:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example columns\n",
    "categorical_cols = train_df.columns[-5:].copy()\n",
    "continuous_cols = train_df.columns[1:-5].copy()\n",
    "\n",
    "# Generate sequences\n",
    "seq_len = 32  # Sequence length (e.g., daily for hourly data)\n",
    "X, y = preprocess_data(train_df, target_col='cmg', seq_len=seq_len, categorical_cols=categorical_cols, continuous_cols=continuous_cols)\n",
    "\n",
    "# Convert to DataLoader\n",
    "class CMGDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "dataset = CMGDataset(X, y)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, y_val = preprocess_data(\n",
    "    val_df,\n",
    "    target_col='cmg',\n",
    "    seq_len=seq_len,\n",
    "    categorical_cols=categorical_cols,\n",
    "    continuous_cols=continuous_cols,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = TensorDataset(\n",
    "    torch.tensor(X_val, dtype=torch.float32),\n",
    "    torch.tensor(y_val, dtype=torch.float32)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataloader = DataLoader(val_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gigle\\anaconda3\\envs\\mia\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "num_features = X.shape[2]  # Total features per time step\n",
    "model = HybridTFTCNN_Reg(\n",
    "    input_size=num_features,       # Total features (categorical + continuous)\n",
    "    cnn_filters=32,                # Number of CNN filters\n",
    "    kernel_size=3,                 # CNN kernel size\n",
    "    transformer_hidden_size=64,    # Hidden size for TFT\n",
    "    num_heads=4,                   # Attention heads\n",
    "    num_layers=2,                  # Number of Transformer layers\n",
    "    output_size=1                  # Single regression target\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2303.7112\n",
      "Epoch 2, Loss: 1446.2472\n",
      "Epoch 3, Loss: 1337.3529\n",
      "Epoch 4, Loss: 1252.1016\n",
      "Epoch 5, Loss: 1184.4239\n",
      "Epoch 6, Loss: 1131.5276\n",
      "Epoch 7, Loss: 1089.8480\n",
      "Epoch 8, Loss: 1036.9404\n",
      "Epoch 9, Loss: 1001.7612\n",
      "Epoch 10, Loss: 980.6072\n",
      "Epoch 11, Loss: 934.6766\n",
      "Epoch 12, Loss: 947.8153\n",
      "Epoch 13, Loss: 896.9920\n",
      "Epoch 14, Loss: 896.3906\n",
      "Epoch 15, Loss: 865.3242\n",
      "Epoch 16, Loss: 858.4259\n",
      "Epoch 17, Loss: 835.5689\n",
      "Epoch 18, Loss: 810.0777\n",
      "Epoch 19, Loss: 810.8415\n",
      "Epoch 20, Loss: 804.6304\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "criterion = nn.MSELoss()  # Regression loss\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "for epoch in range(20):  # Number of epochs\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for X_batch, y_batch in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(X_batch)\n",
    "        loss = criterion(predictions.squeeze(-1), y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {epoch_loss / len(dataloader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 793.0645, Valid Loss: 16720.5990, Valid MAE: 90.4759\n",
      "Epoch 2, Train Loss: 781.8277, Valid Loss: 16842.5641, Valid MAE: 91.8608\n",
      "Epoch 3, Train Loss: 795.5949, Valid Loss: 19363.0241, Valid MAE: 97.9672\n",
      "Epoch 4, Train Loss: 756.4075, Valid Loss: 19362.9383, Valid MAE: 96.1161\n",
      "Epoch 5, Train Loss: 735.8483, Valid Loss: 17588.3249, Valid MAE: 92.7885\n",
      "Epoch 6, Train Loss: 747.1645, Valid Loss: 17851.2944, Valid MAE: 92.7315\n",
      "Epoch 7, Train Loss: 730.1499, Valid Loss: 16395.6502, Valid MAE: 89.0325\n",
      "Epoch 8, Train Loss: 716.6324, Valid Loss: 17255.0940, Valid MAE: 93.9357\n",
      "Epoch 9, Train Loss: 709.9876, Valid Loss: 16899.0866, Valid MAE: 89.9843\n",
      "Epoch 10, Train Loss: 702.8071, Valid Loss: 14511.5911, Valid MAE: 82.4931\n",
      "Epoch 11, Train Loss: 697.7666, Valid Loss: 12804.2702, Valid MAE: 76.1442\n",
      "Epoch 12, Train Loss: 699.4595, Valid Loss: 17614.1641, Valid MAE: 91.4435\n",
      "Epoch 13, Train Loss: 730.2030, Valid Loss: 21680.9246, Valid MAE: 99.8236\n",
      "Epoch 14, Train Loss: 844.3246, Valid Loss: 24113.9345, Valid MAE: 109.1948\n",
      "Epoch 15, Train Loss: 764.8681, Valid Loss: 25854.9629, Valid MAE: 114.6200\n",
      "Epoch 16, Train Loss: 719.5646, Valid Loss: 19889.0531, Valid MAE: 98.7079\n",
      "Epoch 17, Train Loss: 677.3437, Valid Loss: 18382.2512, Valid MAE: 93.7265\n",
      "Epoch 18, Train Loss: 693.2539, Valid Loss: 18222.6004, Valid MAE: 92.5110\n",
      "Epoch 19, Train Loss: 648.8912, Valid Loss: 20547.6347, Valid MAE: 100.8060\n",
      "Epoch 20, Train Loss: 659.1210, Valid Loss: 23191.1056, Valid MAE: 106.8696\n"
     ]
    }
   ],
   "source": [
    "## Training Loop 2.0\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Variables to track the best model\n",
    "best_valid_loss = float('inf')\n",
    "best_model_weights = None\n",
    "\n",
    "for epoch in range(20):  # Number of epochs\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for X_batch, y_batch in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(X_batch)\n",
    "        loss = criterion(predictions.squeeze(-1), y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    train_loss = epoch_loss / len(dataloader)\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    valid_loss = 0\n",
    "    all_y_pred = []\n",
    "    all_y_true = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_val, y_val in val_dataloader:  # Use a separate dataloader for validation data\n",
    "            val_predictions = model(X_val)\n",
    "            val_loss = criterion(val_predictions.squeeze(-1), y_val)\n",
    "            valid_loss += val_loss.item()\n",
    "\n",
    "            # Store predictions and true values for MAE calculation\n",
    "            all_y_pred.extend(val_predictions.squeeze(-1).tolist())\n",
    "            all_y_true.extend(y_val.tolist())\n",
    "\n",
    "    valid_loss /= len(val_dataloader)\n",
    "    valid_mae = mean_absolute_error(all_y_true, all_y_pred)\n",
    "\n",
    "    # Save the best model weights\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        best_model_weights = model.state_dict()  # Save the weights of the best model\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch + 1}, \"\n",
    "        f\"Train Loss: {train_loss:.4f}, \"\n",
    "        f\"Valid Loss: {valid_loss:.4f}, \"\n",
    "        f\"Valid MAE: {valid_mae:.4f}\"\n",
    "    )\n",
    "\n",
    "# Load the best model weights after training\n",
    "if best_model_weights:\n",
    "    model.load_state_dict(best_model_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = preprocess_data(\n",
    "    test_df,\n",
    "    target_col='cmg',\n",
    "    seq_len=seq_len,\n",
    "    categorical_cols=categorical_cols,\n",
    "    continuous_cols=continuous_cols\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get predictions\n",
    "# y_pred = model.predict(X_test)\n",
    "\n",
    "# # Flatten predictions if needed (e.g., if predictions are in shape (N, 1))\n",
    "# y_pred = y_pred.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the model is in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Convert test data to a PyTorch tensor\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "\n",
    "# Disable gradient computation during prediction\n",
    "with torch.no_grad():\n",
    "    y_pred_tensor = model(X_test_tensor)\n",
    "\n",
    "# Convert predictions back to a NumPy array\n",
    "y_pred = y_pred_tensor.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-196.12856 ],\n",
       "       [-219.4969  ],\n",
       "       [-246.51611 ],\n",
       "       ...,\n",
       "       [  20.310137],\n",
       "       [  56.49498 ],\n",
       "       [  59.64724 ]], dtype=float32)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = y_pred.flatten()\n",
    "\n",
    "# Adjust test_dt and test_cmg to match the reduced length after preprocessing\n",
    "adjusted_test_dt = test_dt.iloc[seq_len:].reset_index(drop=True)\n",
    "adjusted_test_cmg = test_cmg.iloc[seq_len:].reset_index(drop=True)\n",
    "\n",
    "# Create the combined DataFrame\n",
    "result_df = pd.DataFrame({\n",
    "    'datetime': adjusted_test_dt,\n",
    "    'y_real': adjusted_test_cmg,\n",
    "    'y_pred': y_pred\n",
    "})\n",
    "\n",
    "# result_df.loc[result_df['y_pred'] <= 0, 'y_pred'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>y_real</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-12-12 14:00:00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-196.128555</td>\n",
       "      <td>tft-cnn_v01_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-12-12 15:00:00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-219.496902</td>\n",
       "      <td>tft-cnn_v01_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-12-12 16:00:00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-246.516113</td>\n",
       "      <td>tft-cnn_v01_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-12-12 17:00:00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-278.591034</td>\n",
       "      <td>tft-cnn_v01_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-12-12 18:00:00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-303.763733</td>\n",
       "      <td>tft-cnn_v01_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4777</th>\n",
       "      <td>2024-06-28 15:00:00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>72.194267</td>\n",
       "      <td>tft-cnn_v01_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4778</th>\n",
       "      <td>2024-06-28 16:00:00</td>\n",
       "      <td>9.03</td>\n",
       "      <td>69.247757</td>\n",
       "      <td>tft-cnn_v01_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4779</th>\n",
       "      <td>2024-06-28 17:00:00</td>\n",
       "      <td>35.36</td>\n",
       "      <td>20.310137</td>\n",
       "      <td>tft-cnn_v01_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4780</th>\n",
       "      <td>2024-06-28 18:00:00</td>\n",
       "      <td>69.48</td>\n",
       "      <td>56.494980</td>\n",
       "      <td>tft-cnn_v01_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4781</th>\n",
       "      <td>2024-06-28 19:00:00</td>\n",
       "      <td>67.99</td>\n",
       "      <td>59.647240</td>\n",
       "      <td>tft-cnn_v01_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4782 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 datetime  y_real      y_pred          model\n",
       "0     2023-12-12 14:00:00    0.00 -196.128555  tft-cnn_v01_1\n",
       "1     2023-12-12 15:00:00    0.00 -219.496902  tft-cnn_v01_1\n",
       "2     2023-12-12 16:00:00    0.00 -246.516113  tft-cnn_v01_1\n",
       "3     2023-12-12 17:00:00    0.00 -278.591034  tft-cnn_v01_1\n",
       "4     2023-12-12 18:00:00    0.00 -303.763733  tft-cnn_v01_1\n",
       "...                   ...     ...         ...            ...\n",
       "4777  2024-06-28 15:00:00    0.00   72.194267  tft-cnn_v01_1\n",
       "4778  2024-06-28 16:00:00    9.03   69.247757  tft-cnn_v01_1\n",
       "4779  2024-06-28 17:00:00   35.36   20.310137  tft-cnn_v01_1\n",
       "4780  2024-06-28 18:00:00   69.48   56.494980  tft-cnn_v01_1\n",
       "4781  2024-06-28 19:00:00   67.99   59.647240  tft-cnn_v01_1\n",
       "\n",
       "[4782 rows x 4 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df['model'] = 'tft-cnn_v01_1'\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_real</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4782.000000</td>\n",
       "      <td>4782.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>55.365004</td>\n",
       "      <td>-73.803337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>51.865822</td>\n",
       "      <td>129.144928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-500.435028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-164.237907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>67.740000</td>\n",
       "      <td>-71.852863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>86.267500</td>\n",
       "      <td>46.547360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>347.930000</td>\n",
       "      <td>144.554169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_real       y_pred\n",
       "count  4782.000000  4782.000000\n",
       "mean     55.365004   -73.803337\n",
       "std      51.865822   129.144928\n",
       "min       0.000000  -500.435028\n",
       "25%       0.000000  -164.237907\n",
       "50%      67.740000   -71.852863\n",
       "75%      86.267500    46.547360\n",
       "max     347.930000   144.554169"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append the result_df to the existing CSV\n",
    "result_df.to_csv('./test_results/tests_consolidated.csv', mode='a', index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4782"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(adjusted_test_cmg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>real</th>\n",
       "      <th>pred</th>\n",
       "      <th>model</th>\n",
       "      <th>fecha_eval</th>\n",
       "      <th>correlative</th>\n",
       "      <th>coincidence</th>\n",
       "      <th>charge_real</th>\n",
       "      <th>charge_pred</th>\n",
       "      <th>discharge_real</th>\n",
       "      <th>discharge_pred</th>\n",
       "      <th>revenue_real</th>\n",
       "      <th>revenue_pred</th>\n",
       "      <th>mae</th>\n",
       "      <th>rmse</th>\n",
       "      <th>bias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-12-12 14:00:00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-196.128555</td>\n",
       "      <td>tft-cnn_v01_1</td>\n",
       "      <td>2023-12-12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>196.128555</td>\n",
       "      <td>196.128555</td>\n",
       "      <td>-196.128555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-12-12 15:00:00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-219.496902</td>\n",
       "      <td>tft-cnn_v01_1</td>\n",
       "      <td>2023-12-12</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>219.496902</td>\n",
       "      <td>219.496902</td>\n",
       "      <td>-219.496902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-12-12 16:00:00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-246.516113</td>\n",
       "      <td>tft-cnn_v01_1</td>\n",
       "      <td>2023-12-12</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>246.516113</td>\n",
       "      <td>246.516113</td>\n",
       "      <td>-246.516113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-12-12 17:00:00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-278.591034</td>\n",
       "      <td>tft-cnn_v01_1</td>\n",
       "      <td>2023-12-12</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>278.591034</td>\n",
       "      <td>278.591034</td>\n",
       "      <td>-278.591034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-12-12 18:00:00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-303.763733</td>\n",
       "      <td>tft-cnn_v01_1</td>\n",
       "      <td>2023-12-12</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>303.763733</td>\n",
       "      <td>303.763733</td>\n",
       "      <td>-303.763733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4777</th>\n",
       "      <td>2024-06-28 15:00:00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>72.194267</td>\n",
       "      <td>tft-cnn_v01_1</td>\n",
       "      <td>2024-06-28</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>72.194267</td>\n",
       "      <td>72.194267</td>\n",
       "      <td>72.194267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4778</th>\n",
       "      <td>2024-06-28 16:00:00</td>\n",
       "      <td>9.03</td>\n",
       "      <td>69.247757</td>\n",
       "      <td>tft-cnn_v01_1</td>\n",
       "      <td>2024-06-28</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-9.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>60.217757</td>\n",
       "      <td>60.217757</td>\n",
       "      <td>60.217757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4779</th>\n",
       "      <td>2024-06-28 17:00:00</td>\n",
       "      <td>35.36</td>\n",
       "      <td>20.310137</td>\n",
       "      <td>tft-cnn_v01_1</td>\n",
       "      <td>2024-06-28</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-35.36</td>\n",
       "      <td>15.049863</td>\n",
       "      <td>15.049863</td>\n",
       "      <td>-15.049863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4780</th>\n",
       "      <td>2024-06-28 18:00:00</td>\n",
       "      <td>69.48</td>\n",
       "      <td>56.494980</td>\n",
       "      <td>tft-cnn_v01_1</td>\n",
       "      <td>2024-06-28</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>69.48</td>\n",
       "      <td>-69.48</td>\n",
       "      <td>12.985020</td>\n",
       "      <td>12.985020</td>\n",
       "      <td>-12.985020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4781</th>\n",
       "      <td>2024-06-28 19:00:00</td>\n",
       "      <td>67.99</td>\n",
       "      <td>59.647240</td>\n",
       "      <td>tft-cnn_v01_1</td>\n",
       "      <td>2024-06-28</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>67.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.342760</td>\n",
       "      <td>8.342760</td>\n",
       "      <td>-8.342760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4782 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                datetime   real        pred          model  fecha_eval  \\\n",
       "0    2023-12-12 14:00:00   0.00 -196.128555  tft-cnn_v01_1  2023-12-12   \n",
       "1    2023-12-12 15:00:00   0.00 -219.496902  tft-cnn_v01_1  2023-12-12   \n",
       "2    2023-12-12 16:00:00   0.00 -246.516113  tft-cnn_v01_1  2023-12-12   \n",
       "3    2023-12-12 17:00:00   0.00 -278.591034  tft-cnn_v01_1  2023-12-12   \n",
       "4    2023-12-12 18:00:00   0.00 -303.763733  tft-cnn_v01_1  2023-12-12   \n",
       "...                  ...    ...         ...            ...         ...   \n",
       "4777 2024-06-28 15:00:00   0.00   72.194267  tft-cnn_v01_1  2024-06-28   \n",
       "4778 2024-06-28 16:00:00   9.03   69.247757  tft-cnn_v01_1  2024-06-28   \n",
       "4779 2024-06-28 17:00:00  35.36   20.310137  tft-cnn_v01_1  2024-06-28   \n",
       "4780 2024-06-28 18:00:00  69.48   56.494980  tft-cnn_v01_1  2024-06-28   \n",
       "4781 2024-06-28 19:00:00  67.99   59.647240  tft-cnn_v01_1  2024-06-28   \n",
       "\n",
       "      correlative  coincidence  charge_real  charge_pred  discharge_real  \\\n",
       "0               1            0            1            0               1   \n",
       "1               2            0            1            0               0   \n",
       "2               3            0            1            0               0   \n",
       "3               4            1            1            1               0   \n",
       "4               5            1            1            1               0   \n",
       "...           ...          ...          ...          ...             ...   \n",
       "4777           16            0            1            0               0   \n",
       "4778           17            0            1            0               0   \n",
       "4779           18            0            0            1               0   \n",
       "4780           19            0            0            1               1   \n",
       "4781           20            0            0            0               1   \n",
       "\n",
       "      discharge_pred  revenue_real  revenue_pred         mae        rmse  \\\n",
       "0                  1          0.00          0.00  196.128555  196.128555   \n",
       "1                  1          0.00          0.00  219.496902  219.496902   \n",
       "2                  1          0.00          0.00  246.516113  246.516113   \n",
       "3                  0          0.00          0.00  278.591034  278.591034   \n",
       "4                  0          0.00          0.00  303.763733  303.763733   \n",
       "...              ...           ...           ...         ...         ...   \n",
       "4777               0          0.00          0.00   72.194267   72.194267   \n",
       "4778               0         -9.03          0.00   60.217757   60.217757   \n",
       "4779               0          0.00        -35.36   15.049863   15.049863   \n",
       "4780               0         69.48        -69.48   12.985020   12.985020   \n",
       "4781               0         67.99          0.00    8.342760    8.342760   \n",
       "\n",
       "            bias  \n",
       "0    -196.128555  \n",
       "1    -219.496902  \n",
       "2    -246.516113  \n",
       "3    -278.591034  \n",
       "4    -303.763733  \n",
       "...          ...  \n",
       "4777   72.194267  \n",
       "4778   60.217757  \n",
       "4779  -15.049863  \n",
       "4780  -12.985020  \n",
       "4781   -8.342760  \n",
       "\n",
       "[4782 rows x 16 columns]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.rename(columns={'y_real': 'real',\n",
    "                          'y_pred': 'pred'}, inplace=True)\n",
    "\n",
    "kpis, kpi_summary = utils.calculate_kpis(result_df, 'datetime', 6, 32)\n",
    "kpis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>factor_coincidence</th>\n",
       "      <th>factor_value</th>\n",
       "      <th>mae</th>\n",
       "      <th>rmse</th>\n",
       "      <th>bias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.408333</td>\n",
       "      <td>0.574869</td>\n",
       "      <td>142.220820</td>\n",
       "      <td>142.220820</td>\n",
       "      <td>-129.549426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.176146</td>\n",
       "      <td>0.399694</td>\n",
       "      <td>99.096770</td>\n",
       "      <td>99.096770</td>\n",
       "      <td>113.427729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.711018</td>\n",
       "      <td>13.393801</td>\n",
       "      <td>13.393801</td>\n",
       "      <td>-427.515549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.394401</td>\n",
       "      <td>49.442496</td>\n",
       "      <td>49.442496</td>\n",
       "      <td>-206.727075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.720608</td>\n",
       "      <td>134.241075</td>\n",
       "      <td>134.241075</td>\n",
       "      <td>-134.241075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.866835</td>\n",
       "      <td>206.727075</td>\n",
       "      <td>206.727075</td>\n",
       "      <td>-24.946182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>427.515549</td>\n",
       "      <td>427.515549</td>\n",
       "      <td>39.501544</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       factor_coincidence  factor_value         mae        rmse        bias\n",
       "count          200.000000    200.000000  200.000000  200.000000  200.000000\n",
       "mean             0.408333      0.574869  142.220820  142.220820 -129.549426\n",
       "std              0.176146      0.399694   99.096770   99.096770  113.427729\n",
       "min              0.000000     -0.711018   13.393801   13.393801 -427.515549\n",
       "25%              0.291667      0.394401   49.442496   49.442496 -206.727075\n",
       "50%              0.416667      0.720608  134.241075  134.241075 -134.241075\n",
       "75%              0.500000      0.866835  206.727075  206.727075  -24.946182\n",
       "max              0.833333      1.000000  427.515549  427.515549   39.501544"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kpi_summary.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "kpis.to_csv('./test_results/kpis_consolidated.csv', mode='a', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
